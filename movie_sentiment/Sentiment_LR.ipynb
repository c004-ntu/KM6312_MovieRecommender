{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Sentiment Analysis Of Movie Reviews </center>\n",
    "### <center> Logistic Regression </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10468, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "rating_df = pd.read_csv('data/rating_auto_label_sentiment_two_classes.csv')\n",
    "\n",
    "# drop unused columns\n",
    "rating_df = rating_df [['review_text','sentiment']]\n",
    "rating_df.head(2)\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10462, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values in any column\n",
    "rating_df = rating_df.dropna()\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Text Pre-processing\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'): #ADJECTIVE\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'): #VERN\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'): #NOUN        \n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'): #ADVERB\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # Tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    # Tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged) \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # If no tag was found, then use the word as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            # Else use the tag to lemmatize the word\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df['review_text'] = df['review_text'].astype(str).fillna('')\n",
    "\n",
    "    # remove white space\n",
    "    df['review_text'] = df['review_text'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # update to lower case\n",
    "    df['review_text'] = df['review_text'].str.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[{}]'.format(re.escape(string.punctuation)), '', regex=True)\n",
    "\n",
    "    # remove special characters\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    "    # remove digits\n",
    "    df['review_text'] = df['review_text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "    # remove non ascii\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "    \n",
    "    # remove URL\n",
    "    df['review_text'] = df['review_text'].str.replace(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    stop_words = stopwords.words('english') + ['br']\n",
    "    stopwords_dict = Counter(stop_words)\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_dict]))\n",
    "\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_result = pd.DataFrame(columns=['task_no', 'model', 'ngram', 'vectorizer', 'max_iter', 'C', 'gamma', 'accuracy', 'wall_time','run_time'])\n",
    "model_no = 1\n",
    "filename=\"result.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>let leave door love beetlejuice edward scissor...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast paced action thriller delivers begin end ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent movie great cast see movie saw one r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write three highpraise review try think bad mo...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well make movie quality write act cinematograp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>true captain america modern comic book version...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movie like wonder otherwise main character wor...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>thought safe go hike bush againalong come mick...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movie great</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sheriff freddy heflin stallone ordinary office...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>michael mann russell crowe al pacino ensemble ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>quentin tarantino genius bring us pulp fiction...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>film mark third reunion martin scorsese robert...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>meet max cady terrific villain role de niro ev...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gladiator favorite film time epic masterpiece ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>read book much well read hitchhiker guide gala...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>roger cobb author separate wife move new house...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>say movie amaze full explosion action set slig...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>felt like tremendous end nolans batman trilogy...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>personally think film par well dark knight whi...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          review_text sentiment\n",
       "0   let leave door love beetlejuice edward scissor...  NEGATIVE\n",
       "1   fast paced action thriller delivers begin end ...  POSITIVE\n",
       "2   excellent movie great cast see movie saw one r...  POSITIVE\n",
       "3   write three highpraise review try think bad mo...  NEGATIVE\n",
       "4   well make movie quality write act cinematograp...  POSITIVE\n",
       "5   true captain america modern comic book version...  POSITIVE\n",
       "6   movie like wonder otherwise main character wor...  POSITIVE\n",
       "7   thought safe go hike bush againalong come mick...  NEGATIVE\n",
       "8                                         movie great  POSITIVE\n",
       "9   sheriff freddy heflin stallone ordinary office...  NEGATIVE\n",
       "10  michael mann russell crowe al pacino ensemble ...  NEGATIVE\n",
       "11  quentin tarantino genius bring us pulp fiction...  POSITIVE\n",
       "12  film mark third reunion martin scorsese robert...  NEGATIVE\n",
       "13  meet max cady terrific villain role de niro ev...  POSITIVE\n",
       "14  gladiator favorite film time epic masterpiece ...  POSITIVE\n",
       "15  read book much well read hitchhiker guide gala...  POSITIVE\n",
       "16  roger cobb author separate wife move new house...  NEGATIVE\n",
       "17  say movie amaze full explosion action set slig...  POSITIVE\n",
       "18  felt like tremendous end nolans batman trilogy...  POSITIVE\n",
       "19  personally think film par well dark knight whi...  POSITIVE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "rating_df = preprocess_text(rating_df)\n",
    "rating_df = remove_stopwords(rating_df)\n",
    "rating_df = lemmatize(rating_df)\n",
    "\n",
    "rating_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2093,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(rating_df.review_text,rating_df.sentiment,test_size = 0.2, random_state=42)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.05 s\n",
      "Wall time: 2.53 s\n",
      "1 - LogisticRegression, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 5000\n",
      "Accuracy: 0.7290969899665551\n",
      "\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 147 ms\n",
      "2 - LogisticRegression, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 5000\n",
      "Accuracy: 0.7501194457716197\n",
      "\n",
      "CPU times: total: 2.31 s\n",
      "Wall time: 8.13 s\n",
      "3 - LogisticRegression, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 5000\n",
      "Accuracy: 0.7539417104634496\n",
      "\n",
      "CPU times: total: 1.56 s\n",
      "Wall time: 3.77 s\n",
      "4 - LogisticRegression, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 5000\n",
      "Accuracy: 0.7649307214524605\n",
      "\n",
      "CPU times: total: 2.77 s\n",
      "Wall time: 11 s\n",
      "5 - LogisticRegression, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 5000\n",
      "Accuracy: 0.7601528905876732\n",
      "\n",
      "CPU times: total: 969 ms\n",
      "Wall time: 3.19 s\n",
      "6 - LogisticRegression, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 5000\n",
      "Accuracy: 0.7606306736741519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression models\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import time \n",
    "from datetime import datetime\n",
    "\n",
    "n_grams = [1,2,3]\n",
    "n_vects = ['cbow', 'tfidf']\n",
    "n_iters = [5000]\n",
    "n_stop_lemmatize = [False, True]\n",
    "\n",
    "for n_gram in n_grams:\n",
    "    for n_vect in n_vects:\n",
    "        if n_vect=='cbow':\n",
    "            # Use all features, remove stopwords, apply unigram, bigram, trigram\n",
    "            vect = CountVectorizer(max_features=None, ngram_range=(1,n_gram))\n",
    "        else:\n",
    "            vect = TfidfVectorizer(max_features=None, ngram_range=(1,n_gram))\n",
    "\n",
    "        # Fit on training data and transform the training data to vector (document-term matrix)\n",
    "        X_train_dtm = vect.fit_transform(X_train)\n",
    "        # display(X_train_dtm)\n",
    "\n",
    "        X_test_dtm = vect.transform(X_test)\n",
    "        # display(X_test_dtm)\n",
    "\n",
    "        for n_iter in n_iters:\n",
    "            # 1. Initialize the LogisticRegression classifier\n",
    "            logreg =  LogisticRegression(max_iter=n_iter, class_weight='balanced')\n",
    "\n",
    "            # 2. Train the classifier on the training data & capture wall time\n",
    "            start_time = time.time()\n",
    "            %time logreg.fit(X_train_dtm, y_train)\n",
    "            end_time = time.time()\n",
    "            wall_time = end_time - start_time\n",
    "\n",
    "            # 3. Predict and evaluate the classifier\n",
    "            y_pred = logreg.predict(X_test_dtm)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # 4. Print result\n",
    "            task_no = str(model_no)\n",
    "            model = 'LogisticRegression'\n",
    "            print(f\"{task_no} - {model}, text_preprocess: {True}, vectorizer: {n_vect}, ngram: {n_gram}, max_iter: {n_iter}\")\n",
    "            print(f\"Accuracy: {accuracy}\\n\")\n",
    "            model_no +=1\n",
    "\n",
    "            # 5. Record result to dataframe, to be exported to csv\n",
    "            new_row = [task_no, model, n_gram, n_vect, n_iter, '', '', accuracy, wall_time, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "            df_result.loc[len(df_result)] = new_row\n",
    "\n",
    "            new_row_df = pd.DataFrame([new_row], columns=df_result.columns)\n",
    "            new_row_df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.67      0.70      0.69       777\n",
      "    POSITIVE       0.82      0.79      0.81      1316\n",
      "\n",
      "    accuracy                           0.76      2093\n",
      "   macro avg       0.74      0.75      0.75      2093\n",
      "weighted avg       0.76      0.76      0.76      2093\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "Report=classification_report(y_test,y_pred)\n",
    "print(Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions: ['POSITIVE' 'NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "# Inference on new data\n",
    "new_reviews = ['A worthy contender for the Animated film of 2024', 'No plot at all. But if you are looking for a good laugh. You will not find that either.']\n",
    "new_reviews_dtm = vect.transform(new_reviews)\n",
    "new_predictions = logreg.predict(new_reviews_dtm)\n",
    "\n",
    "print(\"New Predictions:\", new_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
