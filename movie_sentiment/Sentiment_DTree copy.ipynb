{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Sentiment Analysis Of Movie Reviews </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10468, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "rating_df = pd.read_csv('data/rating_auto_label_sentiment_two_classes.csv')\n",
    "\n",
    "# drop unused columns\n",
    "rating_df = rating_df [['review_text','sentiment']]\n",
    "rating_df.head(2)\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10462, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values in any column\n",
    "rating_df = rating_df.dropna()\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Text Pre-processing\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'): #ADJECTIVE\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'): #VERN\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'): #NOUN        \n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'): #ADVERB\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # Tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    # Tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged) \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # If no tag was found, then use the word as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            # Else use the tag to lemmatize the word\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df['review_text'] = df['review_text'].astype(str).fillna('')\n",
    "\n",
    "    # remove white space\n",
    "    df['review_text'] = df['review_text'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # update to lower case\n",
    "    df['review_text'] = df['review_text'].str.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[{}]'.format(re.escape(string.punctuation)), '', regex=True)\n",
    "\n",
    "    # remove special characters\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    "    # remove digits\n",
    "    df['review_text'] = df['review_text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "    # remove non ascii\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "    \n",
    "    # remove URL\n",
    "    df['review_text'] = df['review_text'].str.replace(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    stop_words = stopwords.words('english') + ['br']\n",
    "    stopwords_dict = Counter(stop_words)\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_dict]))\n",
    "\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_result = pd.DataFrame(columns=['model', 'task_no', 'vectorizer', 'ngram', 'max_iter', 'C', 'gamma', 'n_estimator', 'lrate', 'test_accuracy', 'wall_time','run_time'])\n",
    "model_no = 1\n",
    "filename=\"output/result_DT.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>let leave door love beetlejuice edward scissor...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast paced action thriller delivers begin end ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent movie great cast see movie saw one r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write three highpraise review try think bad mo...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well make movie quality write act cinematograp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text sentiment\n",
       "0  let leave door love beetlejuice edward scissor...  NEGATIVE\n",
       "1  fast paced action thriller delivers begin end ...  POSITIVE\n",
       "2  excellent movie great cast see movie saw one r...  POSITIVE\n",
       "3  write three highpraise review try think bad mo...  NEGATIVE\n",
       "4  well make movie quality write act cinematograp...  POSITIVE"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "rating_df = preprocess_text(rating_df)\n",
    "rating_df = remove_stopwords(rating_df)\n",
    "rating_df = lemmatize(rating_df)\n",
    "\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8369,)\n",
      "(1046,)\n",
      "(1047,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(rating_df.review_text,rating_df.sentiment,test_size = 0.2, random_state=42)\n",
    "\n",
    "# 80% training, 20% temporary\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(rating_df.review_text, rating_df.sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# 10% validation, 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Pruning: 0.624282982791587\n",
      "Test Accuracy after Pruning: 0.6341929321872015\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import time \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "vect = TfidfVectorizer(max_features=None, ngram_range=(1,3), stop_words='english', lowercase=True, strip_accents='ascii')\n",
    "\n",
    "# Fit on training data and transform the training data to vector (document-term matrix)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "# display(X_train_dtm)\n",
    "\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "# display(X_val_dtm)\n",
    "\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "# display(X_test_dtm)\n",
    "\n",
    "# Train the full decision tree without pruning constraints\n",
    "full_tree = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "full_tree.fit(X_train_dtm, y_train)\n",
    "\n",
    "# Function to prune the tree\n",
    "def prune_tree(tree, alpha):\n",
    "    # Get the tree structure\n",
    "    tree_ = tree.tree_\n",
    "    # Initialize a list to store nodes to prune\n",
    "    nodes_to_prune = []\n",
    "\n",
    "    # Traverse the tree and mark nodes for pruning\n",
    "    def traverse(node):\n",
    "        if tree_.children_left[node] != _tree.TREE_LEAF:\n",
    "            traverse(tree_.children_left[node])\n",
    "            traverse(tree_.children_right[node])\n",
    "            # Prune if the node's impurity decrease is less than alpha\n",
    "            if tree_.impurity[node] < alpha:\n",
    "                nodes_to_prune.append(node)\n",
    "\n",
    "    traverse(0)\n",
    "\n",
    "    # Prune the marked nodes\n",
    "    for node in nodes_to_prune:\n",
    "        tree_.children_left[node] = _tree.TREE_LEAF\n",
    "        tree_.children_right[node] = _tree.TREE_LEAF\n",
    "\n",
    "# Apply post-pruning with a chosen alpha value\n",
    "alpha = 0.01 \n",
    "prune_tree(full_tree, alpha)\n",
    "\n",
    "# Evaluate the pruned tree on the validation set\n",
    "y_val_pred = full_tree.predict(X_val_dtm)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy after Pruning: {val_accuracy}\")\n",
    "\n",
    "# Final evaluation on the test set\n",
    "y_test_pred = full_tree.predict(X_test_dtm)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Test Accuracy after Pruning: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_y_test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Print the classification report of the best model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_y_test_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_model)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_accuracy)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_y_test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the classification report of the best model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "if best_y_test_pred is not None:\n",
    "    print(\"The best model:\", best_model)\n",
    "    print(\"The best accuracy:\", best_accuracy)\n",
    "\n",
    "    Report=classification_report(y_test,best_y_test_pred)\n",
    "    print(\"Classification Report of the Best Model:\\n\")\n",
    "    print(Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions: ['POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "# Inference on new data\n",
    "# new_reviews = ['A worthy contender for the Animated film of 2024', 'No plot at all. But if you are looking for a good laugh. You will not find that either.']\n",
    "new_reviews = [\n",
    "    \"I absolutely love this movie! It was amazing.\",\n",
    "    \"This movie was terrible, I hated every second of it.\", \n",
    "    \"while this movie is not intended for everyone, it is good for someone has no brain\", \n",
    "    \"let's watch it only when it is free to watch, i will not pay for it\",\n",
    "    'A worthy contender for the Animated film of 2024', \n",
    "    'No plot at all. But if you are looking for a good laugh. You will not find that either.'\n",
    "]\n",
    "\n",
    "new_reviews_dtm = vect.transform(new_reviews)\n",
    "new_predictions = decision_tree.predict(new_reviews_dtm)\n",
    "\n",
    "print(\"New Predictions:\", new_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
