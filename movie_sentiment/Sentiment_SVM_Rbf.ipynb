{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Sentiment Analysis Of Movie Reviews </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10468, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "rating_df = pd.read_csv('data/rating_auto_label_sentiment_two_classes.csv')\n",
    "\n",
    "# drop unused columns\n",
    "rating_df = rating_df [['review_text','sentiment']]\n",
    "rating_df.head(2)\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10462, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values in any column\n",
    "rating_df = rating_df.dropna()\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Text Pre-processing\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'): #ADJECTIVE\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'): #VERN\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'): #NOUN        \n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'): #ADVERB\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # Tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    # Tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged) \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # If no tag was found, then use the word as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            # Else use the tag to lemmatize the word\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df['review_text'] = df['review_text'].astype(str).fillna('')\n",
    "\n",
    "    # remove white space\n",
    "    df['review_text'] = df['review_text'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # update to lower case\n",
    "    df['review_text'] = df['review_text'].str.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[{}]'.format(re.escape(string.punctuation)), '', regex=True)\n",
    "\n",
    "    # remove special characters\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    "    # remove digits\n",
    "    df['review_text'] = df['review_text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "    # remove non ascii\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    stop_words = stopwords.words('english') + ['br']\n",
    "    stopwords_dict = Counter(stop_words)\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_dict]))\n",
    "\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_result = pd.DataFrame(columns=['model', 'task_no', 'vectorizer', 'ngram', 'max_iter', 'C', 'gamma', 'tree_param', 'n_estimator', 'lrate', 'test_accuracy', 'wall_time','run_time'])\n",
    "model_no = 1\n",
    "filename=\"output/result_SVM_RBF.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>let leave door love beetlejuice edward scissor...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast paced action thriller delivers begin end ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent movie great cast see movie saw one r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write three highpraise review try think bad mo...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well make movie quality write act cinematograp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text sentiment\n",
       "0  let leave door love beetlejuice edward scissor...  NEGATIVE\n",
       "1  fast paced action thriller delivers begin end ...  POSITIVE\n",
       "2  excellent movie great cast see movie saw one r...  POSITIVE\n",
       "3  write three highpraise review try think bad mo...  NEGATIVE\n",
       "4  well make movie quality write act cinematograp...  POSITIVE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "rating_df = preprocess_text(rating_df)\n",
    "rating_df = remove_stopwords(rating_df)\n",
    "rating_df = lemmatize(rating_df)\n",
    "\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8369,)\n",
      "(1046,)\n",
      "(1047,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(rating_df.review_text,rating_df.sentiment,test_size = 0.2, random_state=42)\n",
    "\n",
    "# 80% training, 20% temporary\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(rating_df.review_text, rating_df.sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# 10% validation, 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.3 s\n",
      "Wall time: 1min 2s\n",
      "RbfSVM - 1, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 100000, C:0.01, gamma:scale\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 50.6 s\n",
      "Wall time: 1min 21s\n",
      "RbfSVM - 2, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 100000, C:0.01, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 54.8 s\n",
      "Wall time: 1min 16s\n",
      "RbfSVM - 3, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 100000, C:1, gamma:scale\n",
      "Test Accuracy: 0.7459407831900668\n",
      "\n",
      "CPU times: total: 1min 5s\n",
      "Wall time: 1min 27s\n",
      "RbfSVM - 4, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 100000, C:1, gamma:auto\n",
      "Test Accuracy: 0.6876790830945558\n",
      "\n",
      "CPU times: total: 40.6 s\n",
      "Wall time: 1min 20s\n",
      "RbfSVM - 5, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 100000, C:100, gamma:scale\n",
      "Test Accuracy: 0.7211079274116523\n",
      "\n",
      "CPU times: total: 14.9 s\n",
      "Wall time: 49.2 s\n",
      "RbfSVM - 6, text_preprocess: True, vectorizer: cbow, ngram: 1, max_iter: 100000, C:100, gamma:auto\n",
      "Test Accuracy: 0.7382999044890163\n",
      "\n",
      "CPU times: total: 52.5 s\n",
      "Wall time: 1min 31s\n",
      "RbfSVM - 7, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000, C:0.01, gamma:scale\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 51.4 s\n",
      "Wall time: 1min 24s\n",
      "RbfSVM - 8, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000, C:0.01, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 6s\n",
      "Wall time: 1min 43s\n",
      "RbfSVM - 9, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000, C:1, gamma:scale\n",
      "Test Accuracy: 0.7621776504297995\n",
      "\n",
      "CPU times: total: 1min 4s\n",
      "Wall time: 1min 38s\n",
      "RbfSVM - 10, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000, C:1, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 54s\n",
      "Wall time: 3min 3s\n",
      "RbfSVM - 11, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000, C:100, gamma:scale\n",
      "Test Accuracy: 0.7526265520534862\n",
      "\n",
      "CPU times: total: 58.5 s\n",
      "Wall time: 1min 33s\n",
      "RbfSVM - 12, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000, C:100, gamma:auto\n",
      "Test Accuracy: 0.6294173829990449\n",
      "\n",
      "CPU times: total: 1min 15s\n",
      "Wall time: 2min 9s\n",
      "RbfSVM - 13, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 100000, C:0.01, gamma:scale\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 19s\n",
      "Wall time: 2min 14s\n",
      "RbfSVM - 14, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 100000, C:0.01, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 10s\n",
      "Wall time: 2min 6s\n",
      "RbfSVM - 15, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 100000, C:1, gamma:scale\n",
      "Test Accuracy: 0.7516714422158548\n",
      "\n",
      "CPU times: total: 1min 12s\n",
      "Wall time: 2min 13s\n",
      "RbfSVM - 16, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 100000, C:1, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 56s\n",
      "Wall time: 3min 13s\n",
      "RbfSVM - 17, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 100000, C:100, gamma:scale\n",
      "Test Accuracy: 0.7392550143266475\n",
      "\n",
      "CPU times: total: 1min 15s\n",
      "Wall time: 2min 11s\n",
      "RbfSVM - 18, text_preprocess: True, vectorizer: cbow, ngram: 2, max_iter: 100000, C:100, gamma:auto\n",
      "Test Accuracy: 0.7191977077363897\n",
      "\n",
      "CPU times: total: 1min 23s\n",
      "Wall time: 2min 26s\n",
      "RbfSVM - 19, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:0.01, gamma:scale\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 14s\n",
      "Wall time: 2min 13s\n",
      "RbfSVM - 20, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:0.01, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 55s\n",
      "Wall time: 3min 5s\n",
      "RbfSVM - 21, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:1, gamma:scale\n",
      "Test Accuracy: 0.7631327602674307\n",
      "\n",
      "CPU times: total: 1min 24s\n",
      "Wall time: 2min 17s\n",
      "RbfSVM - 22, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:1, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 3min 17s\n",
      "Wall time: 5min 48s\n",
      "RbfSVM - 23, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:100, gamma:scale\n",
      "Test Accuracy: 0.7602674307545367\n",
      "\n",
      "CPU times: total: 33.9 s\n",
      "Wall time: 1min 45s\n",
      "RbfSVM - 24, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:100, gamma:auto\n",
      "Test Accuracy: 0.6294173829990449\n",
      "\n",
      "CPU times: total: 16.1 s\n",
      "Wall time: 1min 39s\n",
      "RbfSVM - 25, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 100000, C:0.01, gamma:scale\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 17.2 s\n",
      "Wall time: 1min 37s\n",
      "RbfSVM - 26, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 100000, C:0.01, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 18.6 s\n",
      "Wall time: 1min 29s\n",
      "RbfSVM - 27, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 100000, C:1, gamma:scale\n",
      "Test Accuracy: 0.7478510028653295\n",
      "\n",
      "CPU times: total: 20.1 s\n",
      "Wall time: 1min 49s\n",
      "RbfSVM - 28, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 100000, C:1, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 47s\n",
      "Wall time: 3min 33s\n",
      "RbfSVM - 29, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 100000, C:100, gamma:scale\n",
      "Test Accuracy: 0.7478510028653295\n",
      "\n",
      "CPU times: total: 1min 28s\n",
      "Wall time: 2min 38s\n",
      "RbfSVM - 30, text_preprocess: True, vectorizer: cbow, ngram: 3, max_iter: 100000, C:100, gamma:auto\n",
      "Test Accuracy: 0.7029608404966571\n",
      "\n",
      "CPU times: total: 1min 37s\n",
      "Wall time: 2min 54s\n",
      "RbfSVM - 31, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000, C:0.01, gamma:scale\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 1min 16s\n",
      "Wall time: 2min 36s\n",
      "RbfSVM - 32, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000, C:0.01, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 35.5 s\n",
      "Wall time: 2min 29s\n",
      "RbfSVM - 33, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000, C:1, gamma:scale\n",
      "Test Accuracy: 0.7574021012416428\n",
      "\n",
      "CPU times: total: 9.7 s\n",
      "Wall time: 1min 48s\n",
      "RbfSVM - 34, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000, C:1, gamma:auto\n",
      "Test Accuracy: 0.37058261700095513\n",
      "\n",
      "CPU times: total: 58.4 s\n",
      "Wall time: 4min 25s\n",
      "RbfSVM - 35, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000, C:100, gamma:scale\n",
      "Test Accuracy: 0.7574021012416428\n",
      "\n",
      "CPU times: total: 21.2 s\n",
      "Wall time: 1min 49s\n",
      "RbfSVM - 36, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000, C:100, gamma:auto\n",
      "Test Accuracy: 0.6294173829990449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM Model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import time \n",
    "from datetime import datetime\n",
    "\n",
    "n_vects = ['cbow','tfidf']\n",
    "n_grams = [1,2,3]\n",
    "n_iters = [100000]\n",
    "Cs = [0.01, 1, 100]\n",
    "gammas = ['scale', 'auto']\n",
    "# n_stop_lemmatize = [False, True]\n",
    "\n",
    "best_model = ''\n",
    "best_accuracy = 0\n",
    "best_y_test_pred = None\n",
    "\n",
    "for n_gram in n_grams:\n",
    "    for n_vect in n_vects:\n",
    "        if n_vect=='cbow':\n",
    "            # Use all features, remove stopwords, apply unigram, bigram, trigram\n",
    "            vect = CountVectorizer(max_features=None, ngram_range=(1,n_gram), stop_words='english', lowercase=True, strip_accents='ascii')\n",
    "        else:\n",
    "            vect = TfidfVectorizer(max_features=None, ngram_range=(1,n_gram), stop_words='english', lowercase=True, strip_accents='ascii')\n",
    "\n",
    "        # Fit on training data and transform the training data to vector (document-term matrix)\n",
    "        X_train_dtm = vect.fit_transform(X_train)\n",
    "        # display(X_train_dtm)\n",
    "\n",
    "        X_val_dtm = vect.transform(X_val)\n",
    "        # display(X_val_dtm)\n",
    "\n",
    "        X_test_dtm = vect.transform(X_test)\n",
    "        # display(X_test_dtm)\n",
    "\n",
    "        for n_iter in n_iters:\n",
    "            for C in Cs:\n",
    "                for gamma in gammas:\n",
    "                    # Initialize the LogisticRegression classifier\n",
    "                    svm_rbf = SVC (max_iter=n_iter, kernel='rbf', C=C, gamma=gamma, class_weight='balanced', random_state=42)\n",
    "\n",
    "                    # Train the classifier on the training data & capture wall time\n",
    "                    start_time = time.time()\n",
    "                    %time svm_rbf.fit(X_train_dtm, y_train)\n",
    "                    end_time = time.time()\n",
    "                    wall_time = end_time - start_time\n",
    "\n",
    "                    # Predict and evaluate the classifier\n",
    "                    y_val_pred = svm_rbf.predict(X_val_dtm)\n",
    "                    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "                    # Final evaluation on test set\n",
    "                    y_test_pred = svm_rbf.predict(X_test_dtm)\n",
    "                    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "                    # Print result\n",
    "                    task_no = str(model_no)\n",
    "                    model = 'RbfSVM'\n",
    "                    print(f\"{model} - {task_no}, text_preprocess: {True}, vectorizer: {n_vect}, ngram: {n_gram}, max_iter: {n_iter}, C:{C}, gamma:{gamma}\")\n",
    "                    print(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "                    model_no +=1\n",
    "\n",
    "                    # Record result to dataframe, to be exported to csv\n",
    "                    # columns=['model', 'task_no', 'vectorizer', 'ngram', 'max_iter', 'C', 'gamma', 'tree_param', 'n_estimator', 'lrate', 'test_accuracy', 'wall_time','run_time']\n",
    "                    new_row = [model, task_no, n_vect, n_gram, n_iter, C, gamma, '', 0, 0, test_accuracy, wall_time, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "                    df_result.loc[len(df_result)] = new_row\n",
    "\n",
    "                    new_row_df = pd.DataFrame([new_row], columns=df_result.columns)\n",
    "                    new_row_df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))\n",
    "\n",
    "                    # Check for the best model\n",
    "                    if test_accuracy > best_accuracy:\n",
    "                        best_model = f\"{model} - {task_no}, text_preprocess: {True}, vectorizer: {n_vect}, ngram: {n_gram}, max_iter: {n_iter}, C:{C}, gamma:{gamma}\"\n",
    "                        best_accuracy = test_accuracy\n",
    "                        best_y_test_pred = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model: RbfSVM - 21, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000, C:1, gamma:scale\n",
      "The best accuracy: 0.7631327602674307\n",
      "Classification Report of the Best Model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.73      0.58      0.64       388\n",
      "    POSITIVE       0.78      0.87      0.82       659\n",
      "\n",
      "    accuracy                           0.76      1047\n",
      "   macro avg       0.75      0.72      0.73      1047\n",
      "weighted avg       0.76      0.76      0.76      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report of the best model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "if best_y_test_pred is not None:\n",
    "    print(\"The best model:\", best_model)\n",
    "    print(\"The best accuracy:\", best_accuracy)\n",
    "\n",
    "    Report=classification_report(y_test,best_y_test_pred)\n",
    "    print(\"Classification Report of the Best Model:\\n\")\n",
    "    print(Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions: ['POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "# Inference on new data\n",
    "# new_reviews = ['A worthy contender for the Animated film of 2024', 'No plot at all. But if you are looking for a good laugh. You will not find that either.']\n",
    "new_reviews = [\n",
    "    \"I absolutely love this movie! It was amazing.\",\n",
    "    \"This movie was terrible, I hated every second of it.\", \n",
    "    \"while this movie is not intended for everyone, it is good for someone has no brain\", \n",
    "    \"let's watch it only when it is free to watch, i will not pay for it\",\n",
    "    'A worthy contender for the Animated film of 2024', \n",
    "    'No plot at all. But if you are looking for a good laugh. You will not find that either.'\n",
    "]\n",
    "\n",
    "new_reviews_dtm = vect.transform(new_reviews)\n",
    "new_predictions = svm_rbf.predict(new_reviews_dtm)\n",
    "\n",
    "print(\"New Predictions:\", new_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
