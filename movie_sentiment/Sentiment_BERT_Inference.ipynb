{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "./output/distilbert-sst-2 does not appear to have a file named config.json. Checkout 'https://huggingface.co/./output/distilbert-sst-2/tree/main' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output/distilbert-sst-2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the model and tokenizer from the saved path\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m DistilBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m DistilBertTokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode (disable dropout, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ceffendy\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:3354\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   3353\u001b[0m     config_path \u001b[38;5;241m=\u001b[39m config \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[1;32m-> 3354\u001b[0m     config, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m   3355\u001b[0m         config_path,\n\u001b[0;32m   3356\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   3357\u001b[0m         return_unused_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3358\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   3359\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m   3360\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   3361\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   3362\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   3363\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   3364\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m   3365\u001b[0m         _from_auto\u001b[38;5;241m=\u001b[39mfrom_auto_class,\n\u001b[0;32m   3366\u001b[0m         _from_pipeline\u001b[38;5;241m=\u001b[39mfrom_pipeline,\n\u001b[0;32m   3367\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3368\u001b[0m     )\n\u001b[0;32m   3369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3370\u001b[0m     \u001b[38;5;66;03m# In case one passes a config to `from_pretrained` + \"attn_implementation\"\u001b[39;00m\n\u001b[0;32m   3371\u001b[0m     \u001b[38;5;66;03m# override the `_attn_implementation` attribute to `attn_implementation` of the kwargs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3375\u001b[0m     \u001b[38;5;66;03m# we pop attn_implementation from the kwargs but this handles the case where users\u001b[39;00m\n\u001b[0;32m   3376\u001b[0m     \u001b[38;5;66;03m# passes manually the config to `from_pretrained`.\u001b[39;00m\n\u001b[0;32m   3377\u001b[0m     config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[1;32mc:\\Users\\ceffendy\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:603\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m revision\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_set_token_in_kwargs(kwargs, token)\n\u001b[1;32m--> 603\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m    605\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    608\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ceffendy\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ceffendy\\anaconda3\\Lib\\site-packages\\transformers\\configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    690\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    691\u001b[0m         configuration_file,\n\u001b[0;32m    692\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    693\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    694\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    695\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    696\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    697\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    698\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    699\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    700\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    701\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    702\u001b[0m     )\n\u001b[0;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ceffendy\\anaconda3\\Lib\\site-packages\\transformers\\utils\\hub.py:373\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[1;32m--> 373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    374\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    375\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m         )\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: ./output/distilbert-sst-2 does not appear to have a file named config.json. Checkout 'https://huggingface.co/./output/distilbert-sst-2/tree/main' for available files."
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "import torch\n",
    "import torch.nn.functional as F  # To use softmax\n",
    "\n",
    "# Path to the saved model and tokenizer\n",
    "model_path = './output/distilbert-sst-2'\n",
    "\n",
    "# Load the model and tokenizer from the saved path\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "# Set the model to evaluation mode (disable dropout, etc.)\n",
    "model.eval()\n",
    "\n",
    "def preprocess_text(text, tokenizer, max_length=256):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    return encoding\n",
    "\n",
    "def predict_sentiment(text, model, tokenizer):\n",
    "    # Preprocess the input text\n",
    "    encoding = preprocess_text(text, tokenizer)\n",
    "    \n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs.logits  # Get the raw prediction scores\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probabilities = F.softmax(logits, dim=-1)  # Apply softmax along the last dimension\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1)  # Get the predicted class (0 for negative, 1 for positive)\n",
    "    \n",
    "    # Map the predicted class to sentiment label\n",
    "    sentiment = 'POSITIVE' if predicted_class.item() == 1 else 'NEGATIVE'\n",
    "    \n",
    "    # Return sentiment and probabilities for each class\n",
    "    positive_prob = probabilities[0][1].item()  # Probability for POSITIVE class\n",
    "    negative_prob = probabilities[0][0].item()  # Probability for NEGATIVE class\n",
    "    \n",
    "    return sentiment, positive_prob, negative_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I absolutely love this movie! It was amazing.\n",
      "Predicted Sentiment: POSITIVE\n",
      "POSITIVE: 0.9998, NEGATIVE: 0.0002\n",
      "\n",
      "Sentence: This movie was terrible, I hated every second of it.\n",
      "Predicted Sentiment: NEGATIVE\n",
      "POSITIVE: 0.0004, NEGATIVE: 0.9996\n",
      "\n",
      "Sentence: while this movie is not intended for everyone, it is good for someone has no brain\n",
      "Predicted Sentiment: NEGATIVE\n",
      "POSITIVE: 0.0683, NEGATIVE: 0.9317\n",
      "\n",
      "Sentence: let's watch it only when it is free to watch, i will not pay for it\n",
      "Predicted Sentiment: NEGATIVE\n",
      "POSITIVE: 0.0671, NEGATIVE: 0.9329\n",
      "\n",
      "Sentence: A worthy contender for the Animated film of 2024\n",
      "Predicted Sentiment: POSITIVE\n",
      "POSITIVE: 0.9996, NEGATIVE: 0.0004\n",
      "\n",
      "Sentence: No plot at all. But if you are looking for a good laugh. You will not find that either.\n",
      "Predicted Sentiment: NEGATIVE\n",
      "POSITIVE: 0.0017, NEGATIVE: 0.9983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample sentences (positive and negative examples)\n",
    "sample_sentences = [\n",
    "    \"I absolutely love this movie! It was amazing.\",\n",
    "    \"This movie was terrible, I hated every second of it.\", \n",
    "    \"while this movie is not intended for everyone, it is good for someone has no brain\", \n",
    "    \"let's watch it only when it is free to watch, i will not pay for it\",\n",
    "    'A worthy contender for the Animated film of 2024', \n",
    "    'No plot at all. But if you are looking for a good laugh. You will not find that either.'\n",
    "]\n",
    "\n",
    "# Perform inference on each sample sentence\n",
    "for sentence in sample_sentences:\n",
    "    sentiment, positive_prob, negative_prob = predict_sentiment(sentence, model, tokenizer)\n",
    "    print(f\"Sentence: {sentence}\\nPredicted Sentiment: {sentiment}\")\n",
    "    print(f\"POSITIVE: {positive_prob:.4f}, NEGATIVE: {negative_prob:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
