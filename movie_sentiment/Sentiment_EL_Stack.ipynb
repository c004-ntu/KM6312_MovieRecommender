{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Sentiment Analysis Of Movie Reviews </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10468, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "rating_df = pd.read_csv('data/rating_auto_label_sentiment_two_classes.csv')\n",
    "\n",
    "# drop unused columns\n",
    "rating_df = rating_df [['review_text','sentiment']]\n",
    "rating_df.head(2)\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10462, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with NaN values in any column\n",
    "rating_df = rating_df.dropna()\n",
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "\n",
    "# Text Pre-processing\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'): #ADJECTIVE\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'): #VERN\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'): #NOUN        \n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'): #ADVERB\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    # Tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    # Tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged) \n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # If no tag was found, then use the word as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            # Else use the tag to lemmatize the word\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def preprocess_text(df):\n",
    "    df['review_text'] = df['review_text'].astype(str).fillna('')\n",
    "\n",
    "    # remove white space\n",
    "    df['review_text'] = df['review_text'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "    # update to lower case\n",
    "    df['review_text'] = df['review_text'].str.lower()\n",
    "\n",
    "    # remove punctuations\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[{}]'.format(re.escape(string.punctuation)), '', regex=True)\n",
    "\n",
    "    # remove special characters\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "\n",
    "    # remove digits\n",
    "    df['review_text'] = df['review_text'].str.replace(r'\\d+', '', regex=True)\n",
    "\n",
    "    # remove non ascii\n",
    "    df['review_text'] = df['review_text'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "    \n",
    "    # remove URL\n",
    "    df['review_text'] = df['review_text'].str.replace(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', regex=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    stop_words = stopwords.words('english') + ['br']\n",
    "    stopwords_dict = Counter(stop_words)\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords_dict]))\n",
    "\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    df['review_text'] = df['review_text'].apply(lambda x: lemmatize_sentence(x))\n",
    "\n",
    "    return df\n",
    "\n",
    "df_result = pd.DataFrame(columns=['model', 'task_no', 'vectorizer', 'ngram', 'max_iter', 'C', 'gamma', 'tree_param', 'n_estimator', 'lrate', 'batch_size', 'num_epoch', 'weight_decay', 'test_accuracy', 'wall_time', 'run_time'])\n",
    "model_no = 1\n",
    "filename=\"output/result_EL.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>let leave door love beetlejuice edward scissor...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fast paced action thriller delivers begin end ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excellent movie great cast see movie saw one r...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>write three highpraise review try think bad mo...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well make movie quality write act cinematograp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text sentiment\n",
       "0  let leave door love beetlejuice edward scissor...  NEGATIVE\n",
       "1  fast paced action thriller delivers begin end ...  POSITIVE\n",
       "2  excellent movie great cast see movie saw one r...  POSITIVE\n",
       "3  write three highpraise review try think bad mo...  NEGATIVE\n",
       "4  well make movie quality write act cinematograp...  POSITIVE"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Preprocessing\n",
    "rating_df = preprocess_text(rating_df)\n",
    "rating_df = remove_stopwords(rating_df)\n",
    "rating_df = lemmatize(rating_df)\n",
    "\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8369,)\n",
      "(1046,)\n",
      "(1047,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(rating_df.review_text,rating_df.sentiment,test_size = 0.2, random_state=42)\n",
    "\n",
    "# 80% training, 20% temporary\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(rating_df.review_text, rating_df.sentiment, test_size=0.2, random_state=42)\n",
    "\n",
    "# 10% validation, 10% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 1s\n",
      "Wall time: 2min 10s\n",
      "Ensemble - 1, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000\n",
      "Test Accuracy: 0.7363896848137536\n",
      "\n",
      "CPU times: total: 4min 12s\n",
      "Wall time: 5min 20s\n",
      "Ensemble - 2, text_preprocess: True, vectorizer: tfidf, ngram: 2, max_iter: 100000\n",
      "Test Accuracy: 0.6723973256924546\n",
      "\n",
      "CPU times: total: 6min 35s\n",
      "Wall time: 8min 35s\n",
      "Ensemble - 3, text_preprocess: True, vectorizer: tfidf, ngram: 3, max_iter: 100000\n",
      "Test Accuracy: 0.664756446991404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensemble Model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import time \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "n_grams = [1, 2, 3]\n",
    "n_iter = 100000\n",
    "n_vect = 'tfidf'\n",
    "C = 1\n",
    "gamma = 'scale'\n",
    "\n",
    "best_model = ''\n",
    "best_accuracy = 0\n",
    "best_y_test_pred = None\n",
    "\n",
    "for n_gram in n_grams:\n",
    "\n",
    "    vect = TfidfVectorizer(max_features=None, ngram_range=(1,n_gram), stop_words='english', lowercase=True, strip_accents='ascii')\n",
    "\n",
    "    # Fit on training data and transform the training data to vector (document-term matrix)\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    # display(X_train_dtm)\n",
    "\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    # display(X_val_dtm)\n",
    "\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    # display(X_test_dtm)\n",
    "\n",
    "    # Initialize, scale, fit\n",
    "    logreg_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('classifier', LogisticRegression(max_iter=n_iter, class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "\n",
    "    svm_linear_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler( with_mean=False)),\n",
    "        ('classifier', LinearSVC(dual=\"auto\", max_iter=n_iter, class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "\n",
    "    svm_rbf_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('classifier', SVC(max_iter=n_iter, kernel='rbf', C=C, gamma=gamma, class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "\n",
    "    decision_tree_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('classifier', DecisionTreeClassifier(class_weight='balanced', random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Create the ensemble model using VotingClassifier\n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "        ('logreg', logreg_pipeline),\n",
    "        # ('svm', svm_linear_pipeline),\n",
    "        ('svm_rbf', svm_rbf_pipeline),\n",
    "        ('dt', decision_tree_pipeline)\n",
    "    ], voting='hard')\n",
    "\n",
    "    # Train the ensemble model\n",
    "    start_time = time.time()\n",
    "    %time ensemble_model.fit(X_train_dtm, y_train)\n",
    "    end_time = time.time()\n",
    "    wall_time = end_time - start_time\n",
    "\n",
    "    # Predict and evaluate the classifier\n",
    "    y_val_pred = ensemble_model.predict(X_val_dtm)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    y_test_pred = ensemble_model.predict(X_test_dtm)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print result\n",
    "    task_no = str(model_no)\n",
    "    model = 'Ensemble'\n",
    "    print(f\"{model} - {task_no}, text_preprocess: {True}, vectorizer: {n_vect}, ngram: {n_gram}, max_iter: {n_iter}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    model_no +=1\n",
    "\n",
    "    # Record result to dataframe, to be exported to csv\n",
    "    # columns=['model', 'task_no', 'vectorizer', 'ngram', 'max_iter', 'C', 'gamma', 'tree_param', 'n_estimator', 'lrate', 'batch_size', 'num_epoch', 'weight_decay', 'test_accuracy', 'wall_time', 'run_time']\n",
    "    new_row = [model, task_no, n_vect, n_gram, n_iter, '', '', 'full_tree', 0, 0, 0, 0, 0, test_accuracy, wall_time, datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n",
    "    df_result.loc[len(df_result)] = new_row\n",
    "\n",
    "    new_row_df = pd.DataFrame([new_row], columns=df_result.columns)\n",
    "    new_row_df.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))\n",
    "\n",
    "    # Check for the best model\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_model = f\"{model} - {task_no}, text_preprocess: {True}, vectorizer: {n_vect}, ngram: {n_gram}, max_iter: {n_iter}\"\n",
    "        best_accuracy = test_accuracy\n",
    "        best_y_test_pred = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model: Ensemble - 1, text_preprocess: True, vectorizer: tfidf, ngram: 1, max_iter: 100000\n",
      "The best accuracy: 0.7363896848137536\n",
      "Classification Report of the Best Model:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.74      0.45      0.56       388\n",
      "    POSITIVE       0.74      0.91      0.81       659\n",
      "\n",
      "    accuracy                           0.74      1047\n",
      "   macro avg       0.74      0.68      0.68      1047\n",
      "weighted avg       0.74      0.74      0.72      1047\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report of the best model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "if best_y_test_pred is not None:\n",
    "    print(\"The best model:\", best_model)\n",
    "    print(\"The best accuracy:\", best_accuracy)\n",
    "\n",
    "    Report=classification_report(y_test,best_y_test_pred)\n",
    "    print(\"Classification Report of the Best Model:\\n\")\n",
    "    print(Report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Predictions: ['POSITIVE' 'NEGATIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE' 'POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "# Inference on new data\n",
    "# new_reviews = ['A worthy contender for the Animated film of 2024', 'No plot at all. But if you are looking for a good laugh. You will not find that either.']\n",
    "new_reviews = [\n",
    "    \"I absolutely love this movie! It was amazing.\",\n",
    "    \"This movie was terrible, I hated every second of it.\", \n",
    "    \"while this movie is not intended for everyone, it is good for someone has no brain\", \n",
    "    \"let's watch it only when it is free to watch, i will not pay for it\",\n",
    "    'A worthy contender for the Animated film of 2024', \n",
    "    'No plot at all. But if you are looking for a good laugh. You will not find that either.'\n",
    "]\n",
    "\n",
    "new_reviews_dtm = vect.transform(new_reviews)\n",
    "new_predictions = ensemble_model.predict(new_reviews_dtm)\n",
    "\n",
    "print(\"New Predictions:\", new_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
